Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  54.742188 MiB  54.742188 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  54.742188 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  57.632812 MiB   2.890625 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.671875 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   2.617188 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  54.742188 MiB  54.742188 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  54.742188 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  57.628906 MiB   2.886719 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.617188 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   2.675781 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  54.742188 MiB  54.742188 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  54.742188 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  57.636719 MiB   2.894531 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.671875 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   2.613281 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  54.746094 MiB  54.746094 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  54.746094 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  57.640625 MiB   2.894531 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.671875 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   2.613281 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  54.742188 MiB  54.742188 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  54.742188 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  57.632812 MiB   2.890625 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.613281 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   2.675781 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  54.746094 MiB  54.746094 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  54.746094 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  57.640625 MiB   2.894531 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.671875 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   2.613281 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.925781 MiB  60.925781 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.925781 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.925781 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.925781 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.925781 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool
    39                                                 - the data from the worker should be sent to a q
    40                                             '''
    41  60.921875 MiB   0.000000 MiB           1       name = current_process().name
    42                                             # open an existing file to read 
    43  60.921875 MiB   0.000000 MiB           1       with h5py.File(in_file, 'r') as f:
    44                                         
    45                                                 # keep the list in RAM 
    46                                                 # data = list(f.keys()) 
    47                                                 # for d in data:
    48                                                 #     q.put(f[d][i]) # file[key][item_array]: for key in keys put item_array
    49                                         
    50  60.921875 MiB   0.000000 MiB          13           for key in f.keys(): 
    51  60.921875 MiB   0.000000 MiB          12               q.put(f[key][item_array])
    52                                                     # q.put(f[key][()]) # prints the entire array
    53                                             # print(name)


Filename: test_writer_multi_mem.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    33  60.921875 MiB  60.921875 MiB           1   @profile(precision=6, stream=fp)
    34                                         def worker(in_file, item_array, q):
    35                                             '''
    36                                             io reading
    37                                                 - reads (?) files with particle path data 
    38                                                 - passes that data to the scintillator pool

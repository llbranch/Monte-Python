Filename: mainTof.py

Line #    Mem usage    Increment  Occurrences   Line Contents
=============================================================
    32  85.1953 MiB  85.1953 MiB           1   @profile(precision=4, stream=fp)
    33                                         # @profile(precision =4)
    34                                         def run(simClass, *arg, **kwargs):
    35  85.1953 MiB   0.0000 MiB           1       import gc
    36  85.1953 MiB   0.0000 MiB           1       freeze_support() # best practice 
    37  85.1953 MiB   0.0000 MiB           1       if arg:
    38  85.1953 MiB   0.0000 MiB           1           simClass.num_particles = int(arg[0])
    39  85.1953 MiB   0.0000 MiB           1           print(f"Generating {simClass.num_particles} particles now...")
    40                                             else:
    41                                                 simClass.num_particles = 1
    42                                                 print(f"Generating {simClass.num_particles} particle now...")
    43  85.1953 MiB   0.0000 MiB           1       simClass.seperation_time = kwargs.get('delta_t', simClass.seperation_time) # in ps
    44  85.1953 MiB   0.0000 MiB           1       logstarttime = perf_counter()
    45                                             # FIND PARTICLE PATH
    46  85.1953 MiB   0.0000 MiB           1       times = []
    47  85.1953 MiB   0.0000 MiB           1       points = []
    48  85.1953 MiB   0.0000 MiB           1       photons = []
    49  85.1953 MiB   0.0000 MiB           1       particleID = []
    50  85.1953 MiB   0.0000 MiB           1       i = 0
    51  85.5664 MiB   0.3711 MiB           1       with Pool(processes=cpu_count(), maxtasksperchild=2) as pool:
    52  86.0469 MiB   0.4805 MiB           1           res = pool.map(simClass.particle_task, range(simClass.num_particles))
    53                                         
    54  86.3320 MiB   0.2852 MiB           1           pool.close()
    55  86.3828 MiB   0.0508 MiB           1           pool.join()
    56                                         
    57                                         
    58                                                 # print(f'SIZE OF RES: ', sys.getsizeof(res))
    59                                                 # start = perf_counter()
    60                                         
    61  87.6914 MiB   0.0000 MiB           2           for (time_i, point_i, photon_i) in res:
    62  86.3828 MiB   0.0000 MiB           1               i = 0
    63  86.5000 MiB   0.1172 MiB           1               times.extend(time_i)
    64  87.2578 MiB   0.7578 MiB           1               points.extend(point_i)
    65  87.5156 MiB   0.2578 MiB           1               photons.extend(photon_i)
    66  87.6914 MiB   0.1758 MiB           1               particleID.extend(np.repeat(i, len(time_i))) # particle it belongs to
    67  87.6914 MiB   0.0000 MiB           1               i += 1
    68                                         
    69                                                 # end = perf_counter() -start
    70                                         
    71  87.6914 MiB   0.0000 MiB           1       logendparticle = perf_counter()
    72  87.8320 MiB   0.1406 MiB           1       N = np.sum(photons)
    73  87.8320 MiB   0.0000 MiB           1       print("Photons generated", N)
    74  88.1016 MiB   0.2695 MiB           1       times = np.asarray(times); points = np.asarray(points); photons = np.asarray(photons); particleID = np.asarray(particleID)
    75                                         
    76                                             # print(f'SIZE OF TIMES, POINTS, ETC: ', sys.getsizeof(times))
    77                                             # print('Time to unpack times,points, etc.', end)
    78                                         
    79                                         
    80                                             # RETURNS A FILE
    81                                             # SPLIT HERE
    82                                             # RUN #2
    83                                             
    84                                         
    85                                             # SIMULATE EACH PHOTON PATH IN BOTH SCINTILLATORS
    86                                             # Gather TOF data
    87  88.1016 MiB   0.0000 MiB           1       T1_input_times = []
    88  88.1016 MiB   0.0000 MiB           1       T4_input_times = []
    89                                             # Gather Extra Data for analysis
    90  88.1016 MiB   0.0000 MiB           1       simClass.T1_prop_dist = []
    91  88.1016 MiB   0.0000 MiB           1       simClass.T4_prop_dist = []
    92  88.1016 MiB   0.0000 MiB           1       simClass.T1_endpoint_dist = []
    93  88.1016 MiB   0.0000 MiB           1       simClass.T4_endpoint_dist = []
    94  88.1016 MiB   0.0000 MiB           1       simClass.T1_prop_times = []
    95  88.1016 MiB   0.0000 MiB           1       simClass.T4_prop_times = []
    96  88.1016 MiB   0.0000 MiB           1       simClass.T1_interactions = []
    97  88.1016 MiB   0.0000 MiB           1       simClass.T4_interactions = []
    98  88.1016 MiB   0.0000 MiB           1       simClass.T1_part_ids = []
    99  88.1016 MiB   0.0000 MiB           1       simClass.T4_part_ids = []
   100  88.1016 MiB   0.0000 MiB           1       T1points = (points[:])[points[:,2] >= simClass.T1z]
   101  88.1016 MiB   0.0000 MiB           1       T1times = (times[:])[points[:,2] >= simClass.T1z]
   102  88.1016 MiB   0.0000 MiB           1       T1photons = (photons[:])[points[:,2] >= simClass.T1z]
   103  88.1016 MiB   0.0000 MiB           1       T1part_ids = (particleID[:])[points[:,2] >= simClass.T1z]
   104  88.1016 MiB   0.0000 MiB           1       T1part_ids = np.repeat(T1part_ids, T1photons.astype(int), axis=0) # big id bank
   105  88.1016 MiB   0.0000 MiB           1       T4points = (points[:])[points[:,2] < simClass.T1z]
   106  88.1016 MiB   0.0000 MiB           1       T4times = (times[:])[points[:,2] < simClass.T1z]
   107  88.1016 MiB   0.0000 MiB           1       T4photons = (photons[:])[points[:,2] < simClass.T1z]
   108  88.1016 MiB   0.0000 MiB           1       T4part_ids = (particleID[:])[points[:,2] < simClass.T1z]
   109  88.3164 MiB   0.2148 MiB           1       T4part_ids = np.repeat(T4part_ids, T4photons.astype(int), axis=0) # big id bank
   110  88.3164 MiB   0.0000 MiB           1       print(f"Photons in T1: {np.sum(T1photons)} and Photons in T4: {np.sum(T4photons)}")
   111  88.3164 MiB   0.0000 MiB           1       del times; del points; del photons; # remove copies
   112                                             # gc.collect()
   113                                         
   114  88.3164 MiB   0.0000 MiB           1       logstartphoton = perf_counter()
   115                                         
   116                                             # check this link https://stackoverflow.com/questions/14749897/python-multiprocessing-memory-usage
   117  88.5352 MiB   0.2188 MiB           1       with Pool(processes=cpu_count(), maxtasksperchild=2) as pool: # this way of making the pool causes all the data to copy! 
   118  88.5352 MiB   0.0000 MiB           1           print("T1 Photon Propagation working...")
   119                                         
   120                                                 # start = perf_counter()
   121  92.1445 MiB   3.6094 MiB           1           T1res = pool.starmap(simClass.scint_taskT1, np.repeat(np.c_[T1points,T1times],T1photons.astype(int), axis=0))
   122                                                 # end = perf_counter() - start
   123                                                 # print("Time to process T1:", end)
   124                                         
   125  92.1484 MiB   0.0039 MiB           1           print("Done!")
   126                                         
   127                                         
   128  92.1484 MiB   0.0000 MiB           1           print("T4 Photon Propagation working...")
   129                                                 # start = perf_counter()
   130 101.4805 MiB   9.3320 MiB           1           T4res = pool.starmap(simClass.scint_taskT4, np.repeat(np.c_[T4points,T4times],T4photons.astype(int), axis=0))
   131                                                 # end = perf_counter() - start
   132                                                 # print("Time to process T4:", end)
   133                                         
   134 101.4805 MiB   0.0000 MiB           1           print("Done!")
   135 101.4805 MiB   0.0000 MiB           1           print("Unzipping reuslts into arrays...")
   136                                         
   137 101.4805 MiB   0.0000 MiB           1           pool.close()
   138 101.4844 MiB   0.0039 MiB           1           pool.join()
   139                                         
   140                                                 # start = perf_counter()
   141 101.4844 MiB   0.0000 MiB       16701           for (T1hit_PMT, T1travel_time, T1tot_dist, T1endpt, T1bounces, T1prop),T1part_id in zip(T1res, T1part_ids): # check if moving starmap here helps
   142 101.4844 MiB   0.0000 MiB       16700               if T1hit_PMT:
   143 101.4844 MiB   0.0000 MiB          37                   T1_input_times.append(T1travel_time)
   144 101.4844 MiB   0.0000 MiB          37                   simClass.T1_prop_dist.append(T1tot_dist)
   145 101.4844 MiB   0.0000 MiB          37                   simClass.T1_endpoint_dist.append(T1endpt)
   146 101.4844 MiB   0.0000 MiB          37                   simClass.T1_prop_times.append(T1prop)
   147 101.4844 MiB   0.0000 MiB          37                   simClass.T1_interactions.append(T1bounces)
   148 101.4844 MiB   0.0000 MiB          37                   simClass.T1_part_ids.append(T1part_id)
   149                                                 # end = perf_counter() - start
   150                                                 # print("Time to unpack T1:", end)
   151                                         
   152                                                 # start = perf_counter()
   153 101.4844 MiB   0.0000 MiB       33637           for (T4hit_PMT, T4travel_time, T4tot_dist, T4endpt, T4bounces, T4prop),T4part_id in zip(T4res, T4part_ids): # check if moving starmap here helps
   154 101.4844 MiB   0.0000 MiB       33636               if T4hit_PMT:
   155 101.4844 MiB   0.0000 MiB           7                   T4_input_times.append(T4travel_time)
   156 101.4844 MiB   0.0000 MiB           7                   simClass.T4_prop_dist.append(T4tot_dist)
   157 101.4844 MiB   0.0000 MiB           7                   simClass.T4_endpoint_dist.append(T4endpt)
   158 101.4844 MiB   0.0000 MiB           7                   simClass.T4_prop_times.append(T4prop)
   159 101.4844 MiB   0.0000 MiB           7                   simClass.T4_interactions.append(T4bounces)
   160 101.4844 MiB   0.0000 MiB           7                   simClass.T4_part_ids.append(T4part_id)
   161                                                 # end = perf_counter() - start
   162                                                 # print("Time to unpack T4:", end)
   163                                         
   164 101.4844 MiB   0.0000 MiB           1       logendtime = perf_counter()
   165                                             # PRINT RESULTS
   166 101.4844 MiB   0.0000 MiB           1       print("TIME ANALYSIS:")
   167 101.4844 MiB   0.0000 MiB           1       pgtime = timedelta(seconds=logendparticle-logstarttime)
   168 101.4844 MiB   0.0000 MiB           1       phtime = timedelta(seconds=logendtime-logstartphoton)
   169 101.4844 MiB   0.0000 MiB           1       ttime = timedelta(seconds=logendtime-logstarttime)
   170 101.4844 MiB   0.0000 MiB           1       print(f"Generation of Particles     {str(pgtime)}")
   171 101.4844 MiB   0.0000 MiB           1       print(f"Simulation of Photon Travel {str(phtime)}")
   172 101.4844 MiB   0.0000 MiB           1       print(f"Total Time Elapsed:         {str(ttime)}")
   173 101.4844 MiB   0.0000 MiB           1       print("RESULTS SUMMARY:")
   174 101.4844 MiB   0.0000 MiB           1       print("HITS on T1",len(T1_input_times))
   175 101.4883 MiB   0.0039 MiB           1       print("RATIO T1   total photons", np.sum(T1photons), "total incident photons", len(T1_input_times), f"ratio={np.sum(T1photons)/len(T1_input_times):.2f}")
   176 101.4883 MiB   0.0000 MiB           1       print("HITS on T4",len(T4_input_times))
   177 101.4883 MiB   0.0000 MiB           1       print("RATIO T4   total photons ", np.sum(T4photons),"total incident photons", len(T4_input_times), f"ratio={np.sum(T4photons)/len(T4_input_times):.2f}")
   178 101.4883 MiB   0.0000 MiB           1       print("DISTANCE: ")
   179 101.4883 MiB   0.0000 MiB           1       del T1points; del T1times; del T1photons; del T4points; del T4times; del T4photons; # remove unused variables
   180                                             # gc.collect()
   181                                         
   182                                             # print(T4_input_times)
   183                                             # BEGIN SIMULATING PMT PULSE
   184 101.4883 MiB   0.0000 MiB           1       signals_channelT1 = []
   185 101.4883 MiB   0.0000 MiB           1       signals_channelT4 = []
   186 101.4883 MiB   0.0000 MiB           1       output_times_channelT1 = []
   187 101.4883 MiB   0.0000 MiB           1       output_times_channelT4 = []
   188 101.4883 MiB   0.0000 MiB           1       signals = []
   189 101.4883 MiB   0.0000 MiB           1       output_times = []
   190 101.4883 MiB   0.0000 MiB          38       for t in T1_input_times:
   191 101.4883 MiB   0.0000 MiB          37           pmtSignal_i = simClass.photontoElectrons(1)
   192 101.4883 MiB   0.0000 MiB          37           output_times.append(simClass.pmt_electron_travel_time+t)
   193 101.4883 MiB   0.0000 MiB          37           output_times_channelT1.append(simClass.pmt_electron_travel_time+t)
   194 101.4883 MiB   0.0000 MiB          37           signals.append(pmtSignal_i)
   195 101.4883 MiB   0.0000 MiB          37           signals_channelT1.append(pmtSignal_i)
   196 101.4883 MiB   0.0000 MiB           8       for t in T4_input_times:
   197 101.4883 MiB   0.0000 MiB           7           pmtSignal_i = simClass.photontoElectrons(1)
   198 101.4883 MiB   0.0000 MiB           7           output_times.append(simClass.pmt_electron_travel_time+t)
   199 101.4883 MiB   0.0000 MiB           7           output_times_channelT4.append(simClass.pmt_electron_travel_time+t)
   200 101.4883 MiB   0.0000 MiB           7           signals.append(pmtSignal_i)
   201 101.4883 MiB   0.0000 MiB           7           signals_channelT4.append(pmtSignal_i)
   202                                         
   203                                             # CONVERTION Electron count to Current and save in array
   204 101.4883 MiB   0.0000 MiB           1       simClass.signals = np.array(signals) * simClass.q / 1e-12 * simClass.artificial_gain # divided by 1ps 
   205 101.4883 MiB   0.0000 MiB           1       simClass.output_times = np.array(output_times)
   206 101.4883 MiB   0.0000 MiB           1       simClass.signals_channelT1 = np.array(signals_channelT1) * simClass.q / 1e-12 * simClass.artificial_gain
   207 101.4883 MiB   0.0000 MiB           1       simClass.signals_channelT4 = np.array(signals_channelT4) * simClass.q / 1e-12 * simClass.artificial_gain * 0.6 # factor to limit pulses to 50miliamps and stop contant comparator firing. however, current should be smaller from Quantum Efficiency and current should be larger from 3kV potential difference across PMT dynodes instead of current 1kV potential difference
   208 101.4883 MiB   0.0000 MiB           1       simClass.output_times_channelT1 = np.array(output_times_channelT1)
   209 101.4883 MiB   0.0000 MiB           1       simClass.output_times_channelT4 = np.array(output_times_channelT4)
   210                                         
   211                                             # Output function
   212                                             # def to_csv(simClass, **kwargs):
   213 137.6094 MiB  36.1211 MiB           1       from scipy.stats import norm # type: ignore 
   214 137.6094 MiB   0.0000 MiB           1       output_extra = kwargs.get('extra_data_only', False)
   215 137.6094 MiB   0.0000 MiB           1       output_both = kwargs.get('output_both', False)
   216                                             # OUTPUT FORMATTING
   217 137.6094 MiB   0.0000 MiB           1       if output_extra or output_both:
   218                                                 print("Exporting Extra Data...")
   219                                                 dft1 = pd.DataFrame({'T1_part_ids':simClass.T1_part_ids,'time':simClass.output_times_channelT1,'T1_prop_dist':simClass.T1_prop_dist,'T1_endpoint_dist':simClass.T1_endpoint_dist, 'T1_prop_times':simClass.T1_prop_times, 'T1_interactions':simClass.T1_interactions})
   220                                                 dft4 = pd.DataFrame({'T4_part_ids':simClass.T4_part_ids,'time':simClass.output_times_channelT4,'T4_prop_dist':simClass.T4_prop_dist,'T4_endpoint_dist':simClass.T4_endpoint_dist, 'T4_prop_times':simClass.T4_prop_times, 'T4_interactions':simClass.T4_interactions})
   221                                                 dft1.to_csv('monte_carlo_extradata'+str(simClass.num_particles)+'chT1_'+str(datetime.now().strftime('%m_%d_%Y'))+'.txt') # default sep=','
   222                                                 dft4.to_csv('monte_carlo_extradata'+str(simClass.num_particles)+'chT4_'+str(datetime.now().strftime('%m_%d_%Y'))+'.txt') # default sep=','
   223                                                 if not output_both:
   224                                                     return
   225 137.6094 MiB   0.0000 MiB           1       print("Exporing to 2 channels...")
   226                                             # for each channel
   227 139.1797 MiB   0.0000 MiB           3       for time,signal,ch in zip([simClass.output_times_channelT1,simClass.output_times_channelT4],[simClass.signals_channelT1,simClass.signals_channelT4],[1,4]):
   228                                         
   229                                                 # from io import StringIO
   230                                                 # from csv import writer 
   231                                                 # output = StringIO()
   232                                                 # csv_writer = writer(output)
   233                                                 
   234 139.1797 MiB   0.0000 MiB           2           print("Smoothing Signals...")
   235 139.1797 MiB   0.0000 MiB           2           t_binned = [0.] # left edges of bins
   236 139.1797 MiB   0.0000 MiB           2           y_binned = [0.]
   237 139.1797 MiB   0.0000 MiB          46           for i,y in enumerate(signal):
   238                                                     # print(f"i={i},t[{i}]={time[i]} y[{i}]={y}")
   239 139.1797 MiB   0.0000 MiB          44               lower_bound = max(time[i]-2*simClass.sigma_smoothing,0) # 2 sigma away backward
   240 139.1797 MiB   0.0000 MiB          44               upper_bound = min(time[i]+2*simClass.sigma_smoothing,max(time)+2*simClass.sigma_smoothing) # 2 sigma away forward
   241                                                     # MAKE NEW DATA CENTERED AROUND PULSE
   242 139.1797 MiB   0.0000 MiB          44               if lower_bound < max(t_binned): # if already binned
   243 139.1797 MiB   0.0000 MiB          42                   lower_bound = t_binned[np.digitize(lower_bound, t_binned)]+simClass.output_bin_width/2
   244 139.1797 MiB   0.0000 MiB          44               cur_x = np.arange(lower_bound,upper_bound,simClass.output_bin_width)+simClass.output_bin_width/2
   245                                                     # print(f"cur_x from {lower_bound}-->{upper_bound}", cur_x)
   246                                                     # ADD DATA IF NEEDED
   247 139.1797 MiB   0.0000 MiB         653               for x in cur_x:
   248 139.1797 MiB   0.0000 MiB         609                   if x > max(t_binned): 
   249 139.1797 MiB   0.0000 MiB          33                       t_binned.append(x)
   250 139.1797 MiB   0.0000 MiB          33                       y_binned.append(0)
   251 139.1797 MiB   0.0000 MiB         576                   elif (np.digitize(x, t_binned)-1 > 0) and (np.digitize(x, t_binned) < len(t_binned)):
   252 139.1797 MiB   0.0000 MiB         556                       index = np.digitize(x, t_binned)
   253 139.1797 MiB   0.0000 MiB         556                       if abs(t_binned[index]-t_binned[index-1]) > simClass.output_bin_width:
   254                                                                 t_binned.insert(index, x) # check if need -1 or just np.digitize()
   255                                                                 y_binned.insert(index, 0) # check 
   256                                                     # GET INDICIES
   257 139.1797 MiB   0.0000 MiB         853               index_lower = [i for i,t in enumerate(t_binned) if t >= lower_bound][0] # left edge in time binned
   258 139.1797 MiB   0.0000 MiB         853               index_upper = [i for i,t in enumerate(t_binned) if t <= upper_bound][-1] # right edge in time binned
   259                                                     # GAUSSIAN SMOOTH
   260 139.1797 MiB   0.0000 MiB          44               gaussian = norm.pdf(t_binned[index_lower:index_upper], loc=time[i], scale=simClass.sigma_smoothing)*simClass.sigma_smoothing*y/4
   261                                                     # ADD TO CORRECT BINS
   262 139.1797 MiB   0.0000 MiB         589               for i,y_add in enumerate(gaussian):
   263 139.1797 MiB   0.0000 MiB         545                   if y_binned[index_lower+i]+y_add < simClass.max_pmt_current_output:
   264 139.1797 MiB   0.0000 MiB         435                       y_binned[index_lower+i] += y_add
   265                                                         else:
   266 137.6094 MiB   0.0000 MiB         110                       y_binned[index_lower+i] = simClass.max_pmt_current_output
   267                                         
   268 139.1797 MiB   1.0469 MiB           2           df = pd.DataFrame({'time':t_binned,'current':y_binned}).sort_values(by=['time'])
   269 139.1797 MiB   0.0000 MiB           2           print("Formatting PWL dataframe...")
   270 139.1797 MiB   0.0000 MiB           2           fill_data = []                                                                      # declare empty array
   271                                                 # begin padding data at time 1/5th bin width before first time stamp
   272 139.1797 MiB   0.0000 MiB           2           fill_data.append([df['time'].iloc[0]-simClass.output_bin_width/5,0])                    # add zero at beginning
   273 139.1797 MiB   0.0000 MiB          35           for i in range(len(df['time'])-1):                                                        # for each time index
   274 139.1797 MiB   0.0000 MiB          33               if abs(df['time'].iloc[i]-df['time'].iloc[i+1]) > simClass.output_bin_width:        # if dt between signals is greater than minimum bin width
   275 139.1797 MiB   0.0000 MiB           1                   fill_data.append([df['time'].iloc[i]+simClass.output_bin_width/5,0])            # place zero after current signal
   276 139.1797 MiB   0.0000 MiB           1                   fill_data.append([df['time'].iloc[i+1]-simClass.output_bin_width/5,0])          # place zero before next signal
   277 139.1797 MiB   0.0000 MiB           2           fill_data.append([df['time'].iloc[-1]+simClass.output_bin_width/5,0])                   # add zero at end
   278 139.1797 MiB   0.0000 MiB           2           fill_data = np.array(fill_data)
   279 139.1797 MiB   0.0000 MiB           2           fill = pd.DataFrame(fill_data, columns=['time','current'])
   280 139.1797 MiB   0.0352 MiB           2           df = pd.concat([fill, df], ignore_index=True).sort_values(by=['time']).reset_index(drop=True)
   281 139.1797 MiB   0.1680 MiB           2           df['time'] = df['time']/1e12
   282 139.1797 MiB   0.0859 MiB           2           df = df[['time', 'current']] # need this for LTSpice PWL current input file to work
   283 139.1797 MiB   0.2344 MiB           2           df.to_csv('monte_carlo_input'+str(simClass.num_particles)+'ch'+str(ch)+'_'+str(datetime.now().strftime('%m_%d_%Y'))+'.txt', float_format='%.13f', header=False, index=False, sep=' ') # PWL file formatting
   284 139.1797 MiB   0.0000 MiB           1       print("Done!")


